{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alex/opt/anaconda3/envs/transformer/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import dataset\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalSelfAttention(nn.Module):\n",
    "    def __init__(self, d_k, d_model, n_heads, max_len):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Assume d_v = d_k\n",
    "        self.d_k = d_k\n",
    "        self.n_heads = n_heads\n",
    "        \n",
    "        self.key = nn.Linear(d_model, d_k * n_heads)\n",
    "        self.query = nn.Linear(d_model, d_k * n_heads)\n",
    "        self.value = nn.Linear(d_model, d_k * n_heads)\n",
    "        \n",
    "        # final linear layer\n",
    "        self.fc = nn.Linear(d_k * n_heads, d_model)\n",
    "        \n",
    "        # causal mask\n",
    "        # make diagonal zeros to avoid having to shift the inputs to make targets\n",
    "        cm = torch.tril(torch.ones(max_len, max_len))\n",
    "        self.register_buffer(\"causal_mask\", cm.view(1, 1, max_len, max_len))\n",
    "        \n",
    "    def forward(self, q, k, v, pad_mask=None):\n",
    "        q = self.query(q) # N x T x (hd_k)\n",
    "        k = self.key(k)   # N x T x (hd_k)\n",
    "        v = self.value(v) # N x T x (hd_v)\n",
    "        \n",
    "        N = q.shape[0]\n",
    "        T = q.shape[1]\n",
    "        \n",
    "        # change shape to:\n",
    "        # (N, T, h, d_k) x (N, h, d_k, T) --> (N, h, T, T)\n",
    "        # in order for matrix multiply to work correctly\n",
    "        q = q.view(N, T, self.n_heads, self.d_k).transpose(1,2)\n",
    "        k = k.view(N, T, self.n_heads, self.d_k).transpose(1,2)\n",
    "        v = v.view(N, T, self.n_heads, self.d_k).transpose(1,2)\n",
    "        \n",
    "        # compute attention weights\n",
    "        # (N, h, T, d_k) x (N, h, d_k, T) --> (N, h, T, T)\n",
    "        attn_scores = q @ k.transpose(-2, -1) / math.sqrt(self.d_k)\n",
    "        if pad_mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(\n",
    "                pad_mask[:, None, None, :] == 0, float('-inf'))\n",
    "        \n",
    "        attn_scores = attn_scores.masked_fill(\n",
    "            self.causal_mask[:, :, :T, :T] == 0, float('-inf'))\n",
    "        attn_weights = F.softmax(attn_scores, dim=-1)\n",
    "        \n",
    "        # compute attention-weighted value\n",
    "        # (N, h, T, T) x (N, h, T, d_k) --> (N, h, T, d_k)\n",
    "        A = attn_weights @ v\n",
    "        \n",
    "        # reshape it back before final linear layer\n",
    "        A = A.transpose(1, 2) # (N, T, h, d_k)\n",
    "        A = A.contiguous().view(N, T, self.d_k * self.n_heads) # (N, T, h*d_k)\n",
    "        \n",
    "        # projection\n",
    "        return self.fc(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_k, d_model, n_heads, max_len, dropout_prob=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.ln1 = nn.LayerNorm(d_model)\n",
    "        self.ln2 = nn.LayerNorm(d_model)\n",
    "        self.mha = CausalSelfAttention(d_k, d_model, n_heads, max_len)\n",
    "        self.ann = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model * 4),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(d_model * 4, d_model),\n",
    "            nn.Dropout(dropout_prob),\n",
    "        )\n",
    "        self.dropout = nn.Dropout(p=dropout_prob)\n",
    "        \n",
    "    def forward(self, x, pad_mask=None):\n",
    "        x = self.ln1(x + self.mha(x,x,x,pad_mask))\n",
    "        x = self.ln2(x + self.ann(x))\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=2048, dropout_prob=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout_prob)\n",
    "        \n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        exp_term = torch.arange(0, d_model, 2)\n",
    "        div_term = torch.exp(exp_term * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(1, max_len, d_model)\n",
    "        pe[0, :, 0::2] = torch.sin(position * div_term)\n",
    "        pe[0, :, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # x.shape: N x T x D\n",
    "        x = x + self.pe[:, :x.size(1), :]\n",
    "        return self.dropout(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 vocab_size,\n",
    "                 max_len,\n",
    "                 d_k,\n",
    "                 d_model,\n",
    "                 n_heads,\n",
    "                 n_layers,\n",
    "                 dropout_prob):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoding = PositionalEncoding(d_model, max_len, dropout_prob)\n",
    "        transformer_blocks = [\n",
    "            TransformerBlock(\n",
    "                d_k,\n",
    "                d_model,\n",
    "                n_heads,\n",
    "                max_len,\n",
    "                dropout_prob) for _ in range(n_layers)]\n",
    "        self.transformer_blocks = nn.Sequential(*transformer_blocks)\n",
    "        self.ln = nn.LayerNorm(d_model)\n",
    "        self.fc = nn.Linear(d_model, vocab_size)\n",
    "    \n",
    "    def forward(self, x, pad_mask=None):\n",
    "        x = self.embedding(x)\n",
    "        x = self.pos_encoding(x)\n",
    "        for block in self.transformer_blocks:\n",
    "            x = block(x, pad_mask)\n",
    "        x = self.ln(x)\n",
    "        x = self.fc(x) # many to many\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Decoder(20_000, 1024, 16, 64, 4, 2, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (embedding): Embedding(20000, 64)\n",
       "  (pos_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (mha): CausalSelfAttention(\n",
       "        (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (ann): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (mha): CausalSelfAttention(\n",
       "        (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (ann): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  (fc): Linear(in_features=64, out_features=20000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randint(0, 20_000, size=(8,512))\n",
    "x_t = torch.tensor(x).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 512, 20000])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = model(x_t)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.ones((8, 512))\n",
    "mask[:, 256:] = 0\n",
    "mask_t = torch.tensor(mask).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 512, 20000])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = model(x_t, mask_t)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/alex/opt/anaconda3/envs/transformer/lib/python3.11/site-packages (4.30.2)\n",
      "Requirement already satisfied: datasets in /Users/alex/opt/anaconda3/envs/transformer/lib/python3.11/site-packages (2.12.0)\n",
      "Requirement already satisfied: filelock in /Users/alex/opt/anaconda3/envs/transformer/lib/python3.11/site-packages (from transformers) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /Users/alex/opt/anaconda3/envs/transformer/lib/python3.11/site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/alex/opt/anaconda3/envs/transformer/lib/python3.11/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/alex/opt/anaconda3/envs/transformer/lib/python3.11/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/alex/opt/anaconda3/envs/transformer/lib/python3.11/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/alex/opt/anaconda3/envs/transformer/lib/python3.11/site-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: requests in /Users/alex/opt/anaconda3/envs/transformer/lib/python3.11/site-packages (from transformers) (2.29.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/alex/opt/anaconda3/envs/transformer/lib/python3.11/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/alex/opt/anaconda3/envs/transformer/lib/python3.11/site-packages (from transformers) (0.3.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/alex/opt/anaconda3/envs/transformer/lib/python3.11/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Users/alex/opt/anaconda3/envs/transformer/lib/python3.11/site-packages (from datasets) (12.0.1)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /Users/alex/opt/anaconda3/envs/transformer/lib/python3.11/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in /Users/alex/opt/anaconda3/envs/transformer/lib/python3.11/site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: xxhash in /Users/alex/opt/anaconda3/envs/transformer/lib/python3.11/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in /Users/alex/opt/anaconda3/envs/transformer/lib/python3.11/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /Users/alex/opt/anaconda3/envs/transformer/lib/python3.11/site-packages (from datasets) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /Users/alex/opt/anaconda3/envs/transformer/lib/python3.11/site-packages (from datasets) (3.8.3)\n",
      "Requirement already satisfied: responses<0.19 in /Users/alex/opt/anaconda3/envs/transformer/lib/python3.11/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/alex/opt/anaconda3/envs/transformer/lib/python3.11/site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /Users/alex/opt/anaconda3/envs/transformer/lib/python3.11/site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/alex/opt/anaconda3/envs/transformer/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/alex/opt/anaconda3/envs/transformer/lib/python3.11/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/alex/opt/anaconda3/envs/transformer/lib/python3.11/site-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/alex/opt/anaconda3/envs/transformer/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/alex/opt/anaconda3/envs/transformer/lib/python3.11/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/alex/opt/anaconda3/envs/transformer/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/alex/opt/anaconda3/envs/transformer/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/alex/opt/anaconda3/envs/transformer/lib/python3.11/site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/alex/opt/anaconda3/envs/transformer/lib/python3.11/site-packages (from requests->transformers) (2023.5.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/alex/opt/anaconda3/envs/transformer/lib/python3.11/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/alex/opt/anaconda3/envs/transformer/lib/python3.11/site-packages (from pandas->datasets) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in /Users/alex/opt/anaconda3/envs/transformer/lib/python3.11/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-14 18:24:18.698637: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = 'distilbert-base-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset glue (/Users/alex/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "100%|██████████| 3/3 [00:00<00:00, 364.83it/s]\n"
     ]
    }
   ],
   "source": [
    "# use the same dataset, just ignore the labels\n",
    "raw_datasets = load_dataset(\"glue\", \"sst2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 67349\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 872\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 1821\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_fn(batch):\n",
    "    return tokenizer(batch['sentence'], truncation=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/alex/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-b711e37212625ef4.arrow\n",
      "Loading cached processed dataset at /Users/alex/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-3b297f82c267f528.arrow\n",
      "Loading cached processed dataset at /Users/alex/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-e4fb4dac4dd3e7d2.arrow\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = raw_datasets.map(tokenize_fn, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label', 'idx', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 67349\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence', 'label', 'idx', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 872\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label', 'idx', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1821\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = tokenized_datasets.remove_columns(\n",
    "    [\"sentence\", \"idx\", \"label\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    tokenized_datasets[\"train\"],\n",
    "    shuffle=True,\n",
    "    batch_size=32,\n",
    "    collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: input_ids v.shape: torch.Size([32, 49])\n",
      "k: attention_mask v.shape: torch.Size([32, 49])\n"
     ]
    }
   ],
   "source": [
    "# check how it works\n",
    "for batch in train_loader:\n",
    "    for k, v in batch.items():\n",
    "        print(\"k:\", k, \"v.shape:\", v.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (embedding): Embedding(28996, 64)\n",
       "  (pos_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (mha): CausalSelfAttention(\n",
       "        (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (ann): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (mha): CausalSelfAttention(\n",
       "        (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (fc): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (ann): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  (fc): Linear(in_features=64, out_features=28996, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Decoder(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    max_len=tokenizer.max_model_input_sizes[checkpoint],\n",
    "    d_k=16,\n",
    "    d_model=64,\n",
    "    n_heads=4,\n",
    "    n_layers=2,\n",
    "    dropout_prob=0.1,\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to encapsulate the training loop\n",
    "def train(model, criterion, optimizer, train_loader, epochs):\n",
    "    train_losses = np.zeros(epochs)\n",
    "    \n",
    "    for it in range(epochs):\n",
    "        model.train()\n",
    "        t0 = datetime.now()\n",
    "        train_loss = []\n",
    "        for batch in train_loader:\n",
    "            # move data to gpu\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # shift targets backwards\n",
    "            targets = batch['input_ids'].clone().detach()\n",
    "            # remove the CLS flag at the beginning & end of the buffer because distilbert data set uses this\n",
    "            targets = torch.roll(targets, shifts=-1, dims=1)\n",
    "            targets[:, -1] = tokenizer.pad_token_id\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(batch['input_ids'], batch['attention_mask'])\n",
    "            # outputs are N x T x V\n",
    "            # PyTorch is expecting N x V x T\n",
    "            # print(\"outputs:\", outputs)\n",
    "            # print(\"targets:\", targets)\n",
    "            loss = criterion(outputs.transpose(2,1), targets)\n",
    "            # N, T, V = outputs.shape\n",
    "            # loss = criterion(outputs.view(N * T, V), targets.view(N * T))\n",
    "            \n",
    "            # Backward and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss.append(loss.item())\n",
    "            \n",
    "        # Get train and test loss\n",
    "        train_loss = np.mean(train_loss)\n",
    "        \n",
    "        # Save losses\n",
    "        train_losses[it] = train_loss\n",
    "            \n",
    "        dt = datetime.now() - t0\n",
    "        print(f'Epoch {it+1}/{epochs}, Train Loss: {train_loss:.4f}, Duration: {dt}')\n",
    "        \n",
    "    return train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15, Train Loss: 5.9552, Duration: 0:23:33.733117\n",
      "Epoch 2/15, Train Loss: 5.0078, Duration: 0:47:23.716784\n",
      "Epoch 3/15, Train Loss: 4.6802, Duration: 1:27:40.672581\n",
      "Epoch 4/15, Train Loss: 4.4877, Duration: 1:49:54.850989\n",
      "Epoch 5/15, Train Loss: 4.3570, Duration: 1:56:49.864811\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_losses \u001b[39m=\u001b[39m train(model, criterion, optimizer, train_loader, epochs\u001b[39m=\u001b[39m\u001b[39m15\u001b[39m)\n",
      "Cell \u001b[0;32mIn[28], line 33\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, criterion, optimizer, train_loader, epochs)\u001b[0m\n\u001b[1;32m     28\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs\u001b[39m.\u001b[39mtranspose(\u001b[39m2\u001b[39m,\u001b[39m1\u001b[39m), targets)\n\u001b[1;32m     29\u001b[0m \u001b[39m# N, T, V = outputs.shape\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39m# loss = criterion(outputs.view(N * T, V), targets.view(N * T))\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \n\u001b[1;32m     32\u001b[0m \u001b[39m# Backward and optimize\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     34\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     35\u001b[0m train_loss\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/transformer/lib/python3.11/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mbackward(\n\u001b[1;32m    489\u001b[0m     \u001b[39mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39minputs\n\u001b[1;32m    490\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/transformer/lib/python3.11/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39m_execution_engine\u001b[39m.\u001b[39mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, accumulate_grad\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_losses = train(model, criterion, optimizer, train_loader, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loader = DataLoader(\n",
    "    tokenized_datasets[\"validation\"],\n",
    "    batch_size=1,\n",
    "    collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "for batch in valid_loader:\n",
    "  # move data to GPU\n",
    "  batch = {k: v.to(device) for k, v in batch.items()}\n",
    "  outputs = model(batch['input_ids'], batch['attention_mask'])\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 28996])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 170,  112,  188,  170, 1363,  117, 8362, 5827, 2523,  102,  102, 1106]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(outputs, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_ids = torch.argmax(outputs, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"a's a good, un intense movie [SEP] [SEP] to\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(prediction_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[CLS] it's a charming and often affecting journey. [SEP]\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(batch['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[CLS] it's a good\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(torch.concat((batch['input_ids'][0, :5], prediction_ids[:, 4])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 1122,  112,  188,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate something\n",
    "prompt = \"it's\"\n",
    "\n",
    "tokenized_prompt = tokenizer(prompt, return_tensors='pt')\n",
    "tokenized_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 28996])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model(\n",
    "    tokenized_prompt['input_ids'][:, :-1].to(device),\n",
    "    tokenized_prompt['attention_mask'][:, :-1].to(device))\n",
    "\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_ids = torch.argmax(outputs[:, -1, :], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(prediction_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate something\n",
    "prompt = \"it's a\"\n",
    "\n",
    "tokenized_prompt = tokenizer(prompt, return_tensors='pt')\n",
    "\n",
    "# prepare inputs + get rid of SEP token at the end\n",
    "input_ids = tokenized_prompt['input_ids'][:, :-1].to(device)\n",
    "mask = tokenized_prompt['attention_mask'][:, :-1].to(device)\n",
    "\n",
    "for _ in range(20):\n",
    "  outputs = model(input_ids, mask)\n",
    "  prediction_id = torch.argmax(outputs[:, -1, :], axis=-1)\n",
    "\n",
    "  input_ids = torch.hstack((input_ids, prediction_id.view(1, 1)))\n",
    "  mask = torch.ones_like(input_ids)\n",
    "\n",
    "  if prediction_id == tokenizer.sep_token_id:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[CLS] it's a good movie [SEP]\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
